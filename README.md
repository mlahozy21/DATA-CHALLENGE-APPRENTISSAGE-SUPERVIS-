# Data Challenge - Apprentissage Supervis√© üéØ

Projet r√©alis√© dans le cadre du cours **Apprentissage Supervis√© Avanc√©** du Master M2 Math√©matiques et Intelligence Artificielle √† l'Universit√© Paris-Saclay (2025).

## üìã Table des mati√®res

- [Vue d'ensemble](#vue-densemble)
- [Challenge 1 : Classification des r√©servations h√¥teli√®res](#challenge-1--classification-des-r√©servations-h√¥teli√®res)
- [Challenge 2 : R√©gression de la popularit√© Spotify](#challenge-2--r√©gression-de-la-popularit√©-spotify)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [R√©sultats](#r√©sultats)
- [Structure du projet](#structure-du-projet)
- [Auteurs](#auteurs)

## Challenge 1 : Classification des r√©servations h√¥teli√®res

### Probl√©matique

Dans le secteur h√¥telier, les annulations et les no-show entra√Ænent des pertes financi√®res importantes. L'objectif est de pr√©dire le statut final d'une r√©servation parmi 3 cat√©gories :

- **0** : Check-out (client s'est pr√©sent√©)
- **1** : Cancel (r√©servation annul√©e)
- **2** : No-Show (client ne s'est pas pr√©sent√©)


## üéµ Challenge 2 : R√©gression de la popularit√© Spotify

### Probl√©matique

L'industrie musicale cherche √† comprendre les facteurs de popularit√© d'un titre. L'objectif est de pr√©dire la popularit√© Spotify (0-100) √† partir des caract√©ristiques audio et m√©tadonn√©es.

## üîß Installation

### Pr√©requis

- Python 3.8+
- pip ou conda

### Installation des d√©pendances

```bash
# Cloner le d√©p√¥t
git clone https://github.com/mlahozy21/DATA-CHALLENGE-APPRENTISSAGE-SUPERVIS-.git
cd DATA-CHALLENGE-APPRENTISSAGE-SUPERVIS-

# Installer les d√©pendances
pip install -r requirements.txt
```

### D√©pendances principales

```
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
lightgbm>=3.3.0
catboost>=1.0.0
joblib>=1.1.0
```

## Utilisation

### Challenge 1 : Classification

```bash
cd classification/

# 1. Entra√Æner les mod√®les de base (L0)
python train_base_models.py

# 2. Entra√Æner le m√©ta-mod√®le (L1)
python train_meta_model.py

# 3. G√©n√©rer les pr√©dictions finales
python predict_stacking.py
```

**Sortie** : `submission.csv` contenant les pr√©dictions pour l'ensemble de test

### Challenge 2 : R√©gression

```bash
cd regression/

# 1. Entra√Æner les mod√®les de base (L0)
python train_base_models.py

# 2. Entra√Æner le m√©ta-mod√®le (L1)
python train_meta_model.py

# 3. G√©n√©rer les pr√©dictions finales
python predict_stacking.py
```

**Sortie** : `submission.csv` contenant les pr√©dictions de popularit√©

### Configuration personnalis√©e

Les hyperparam√®tres et chemins peuvent √™tre modifi√©s dans `config.py` :

```python
# Exemple : modifier le learning rate de LightGBM
LGBM_PARAMS = {
    'learning_rate': 0.01,  # Modifier ici
    'n_estimators': 3000,
    'num_leaves': 35,
    # ...
}
```


## Auteurs

**Master 2 Math√©matiques et Intelligence Artificielle - Universit√© Paris-Saclay**

- **Marcos Lahoz**
- **Judith Le Roy**
- **Bingjian Jiang**

**Cours** : Apprentissage Supervis√© et Data Challenge  
**Date** : Novembre 2025

## üìö R√©f√©rences

- Ke et al. (2017). *LightGBM: A Highly Efficient Gradient Boosting Decision Tree*. NeurIPS.
- Prokhorenkova et al. (2018). *CatBoost: unbiased boosting with categorical features*. NeurIPS.
- Wolpert (1992). *Stacked Generalization*. Neural Networks, 5(2):241-259.

## License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---
